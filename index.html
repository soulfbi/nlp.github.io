<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Java Code</title>
</head>

<body>

    <pre id="discrete">
        #Q1:Solving Discrete Routing Optimization in NoC using Evolutionary Genetic Algorithms.
import random, heapq, collections, itertools, json, os, tempfile
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ---- helpers (mesh, OE, GA, surrogate) ----
def mesh_neighbors(x, y, W, H):
    for dx, dy, port in [(1,0,'E'),(-1,0,'W'),(0,1,'N'),(0,-1,'S')]:
        nx, ny = x+dx, y+dy
        if 0 <= nx < W and 0 <= ny < H:
            yield (nx, ny, port)

def mesh_links(W,H):
    links = []
    for y in range(H):
        for x in range(W):
            for nx,ny,_ in mesh_neighbors(x,y,W,H):
                links.append(((x,y),(nx,ny)))
    return links

def oe_legal(prev, curr, nxt):
    if prev is None: return True
    x, y = curr
    px, py = prev
    nx, ny = nxt
    dx1, dy1 = x-px, y-py
    dx2, dy2 = nx-x, ny-y
    if x % 2 == 0 and dx1==0 and dx2==-1: return False
    if x % 2 == 1 and dx1==1 and dx2!=0: return False
    return True

def random_chromosome(W,H, wmin=1, wmax=10):
    return {edge: random.randint(wmin,wmax) for edge in mesh_links(W,H)}

def shortest_path_oe(weights, W,H, s, d):
    INF = 10**9
    dist = {}
    prev = {}
    start = (s, None)
    dist[start] = 0
    pq = [(0, start)]
    while pq:
        c, (u, pu) = heapq.heappop(pq)
        if u == d:
            path = [d]
            state = (d, pu)
            while state in prev:
                (u2, pu2) = prev[state]
                path.append(u2)
                state = (u2, pu2)
            return list(reversed(path))
        ux, uy = u
        for vx,vy,_ in mesh_neighbors(ux,uy,W,H):
            if pu is not None and not oe_legal(pu, u, (vx,vy)):
                continue
            w = weights.get(((ux,uy),(vx,vy)), 10)
            nv = ((vx,vy), u)
            nd = c + w
            if nv not in dist or nd < dist[nv]:
                dist[nv] = nd
                prev[nv] = (u, pu)
                heapq.heappush(pq, (nd, nv))
    return None

def decode_routes(weights, W,H, traffic_pairs):
    routes = {}
    for s,d in traffic_pairs:
        p = shortest_path_oe(weights,W,H,s,d)
        if p is None: return None
        routes[(s,d)] = p
    return routes

def simulate_surrogate(routes, inj_matrix, link_capacity=1.0):
    load = collections.defaultdict(float)
    for (s,d), path in routes.items():
        demand = inj_matrix.get((s,d), 0.0)
        for i in range(len(path)-1):
            u, v = path[i], path[i+1]
            load[(u,v)] += demand
    max_util = 0.0
    delay_sum = 0.0; demand_sum = 0.0
    for (u,v), l in load.items():
        util = l / link_capacity
        if util >= 1.0:
            return 1e9 + 1e6*(util-1.0), load
        max_util = max(max_util, util)
        if l > 0:
            delay_sum += l * (1.0 / (1.0 - util))
            demand_sum += l
    avg_delay = (delay_sum/demand_sum) if demand_sum>0 else 0.0
    energy = sum(load.values())
    fitness = 0.6*avg_delay + 0.3*max_util + 0.1*energy
    return fitness, load

def crossover(a,b, px=0.5):
    c = {}
    for k in a:
        c[k] = a[k] if random.random()&lt;px else b[k]
    return c

def mutate(ch, p=0.08, step=1, wmin=1, wmax=10):
    new = ch.copy()
    for k in list(new.keys()):
        if random.random() &lt; p:
            new[k] = max(wmin, min(wmax, new[k] + random.choice([-step,-1,1,step])))
    return new

def make_population(n, W,H):
    return [random_chromosome(W,H) for _ in range(n)]

def evolve_and_track(W=4,H=4, pop_size=20, gens=20, elite=3):
    pairs = []
    inj = {}
    base_demand = 0.005
    for y1 in range(H):
        for x1 in range(W):
            for y2 in range(H):
                for x2 in range(W):
                    if (x1,y1) != (x2,y2):
                        pairs.append(((x1,y1),(x2,y2)))
                        inj[((x1,y1),(x2,y2))] = base_demand
    pop = make_population(pop_size,W,H)
    history = {'best_fitness': [], 'avg_fitness': [], 'best_chrom': None}
    best_overall = (1e18, None, None)
    for g in range(gens):
        scored = []
        for ch in pop:
            routes = decode_routes(ch,W,H,pairs)
            if routes is None:
                fitness = 1e12; load = {}
            else:
                fitness, load = simulate_surrogate(routes, inj, link_capacity=1.0)
            scored.append((fitness, ch, routes, load))
        scored.sort(key=lambda x:x[0])
        fit_vals = [s[0] for s in scored]
        history['best_fitness'].append(fit_vals[0])
        history['avg_fitness'].append(sum(fit_vals)/len(fit_vals))
        if scored[0][0] &lt; best_overall[0]:
            best_overall = (scored[0][0], scored[0][3], scored[0][2])
            history['best_chrom'] = scored[0][1]
        newpop = [scored[i][1] for i in range(min(elite, len(scored)))]
        def tournament():
            a,b = random.sample(scored, 2)
            return a if a[0]&lt;b[0] else b
        while len(newpop) &lt; pop_size:
            p1 = tournament()[1]; p2 = tournament()[1]
            child = crossover(p1,p2,px=0.5)
            child = mutate(child, p=0.08, step=1)
            newpop.append(child)
        pop = newpop
    return history, best_overall

# ---- run & plot ----
random.seed(42)
history, best = evolve_and_track(W=4,H=4,pop_size=20,gens=20,elite=3)

plt.figure()
plt.plot(history['best_fitness'], label='best fitness')
plt.plot(history['avg_fitness'], label='avg fitness')
plt.xlabel('Generation'); plt.ylabel('Fitness (lower better)')
plt.title('GA Fitness over Generations (4x4 demo)')
plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

best_fitness, best_loads, best_routes = best[0], best[1], best[2]
if best_loads is None:
    print("No valid solution found.")
else:
    rows = [{'from':str(u),'to':str(v),'util':float(l)} for (u,v), l in best_loads.items()]
    df_links = pd.DataFrame(rows)
    print(df_links.head(12).to_string())

    plt.figure(); plt.hist(df_links['util'], bins=15)
    plt.xlabel('Utilization (flits/cycle)'); plt.ylabel('Number of directed links')
    plt.title('Histogram of directed link utilizations (best solution)'); plt.grid(True); plt.tight_layout(); plt.show()

    # heatmaps (undirected combined)
    W,H = 4,4
    undirected = collections.defaultdict(float)
    for (u,v), l in best_loads.items():
        a = tuple(u); b = tuple(v)
        key = tuple(sorted([a,b]))
        undirected[key] += l
    import numpy as np
    horiz = np.zeros((H, W-1)); vert = np.zeros((H-1, W))
    for ((a,b), val) in undirected.items():
        (ax,ay),(bx,by) = a,b
        if ay == by:
            x = min(ax,bx); y = ay; horiz[y,x] = val
        elif ax == bx:
            x = ax; y = min(ay,by); vert[y,x] = val
    plt.figure(); plt.imshow(horiz, aspect='auto'); plt.title('Horizontal edge loads'); plt.colorbar(); plt.tight_layout(); plt.show()
    plt.figure(); plt.imshow(vert, aspect='auto'); plt.title('Vertical edge loads'); plt.colorbar(); plt.tight_layout(); plt.show()

# --- Safe JSON export ---
def safe_serialize(obj):
    """Recursively convert tuples to strings for JSON serialization."""
    if isinstance(obj, dict):
        return {str(k): safe_serialize(v) for k, v in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [safe_serialize(x) for x in obj]
    else:
        return obj

summary = {
    'history': safe_serialize(history),
    'best_fitness_value': float(best_fitness),
    'best_loads': safe_serialize(best_loads),
    'sample_routes': safe_serialize(dict(list(best_routes.items())[:10]))
}

tmpfile = os.path.join(tempfile.gettempdir(), 'noc_ga_summary_fixed.json')
with open(tmpfile, 'w') as f:
    json.dump(summary, f, indent=2)

print(f"✅ Saved serializable summary to: {tmpfile}")


    </pre>

    <pre id="cnn">
        # To build a simple CNN that can learn and predict the next routing direction in Network-on-Chip (NoC) based on the current network state

import torch, random
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# XY Routing Label
def xy_label(cur, dst):
    cx, cy = cur; dx, dy = dst
    if cur == dst: return 0
    if cx &lt; dx: return 3
    if cx > dx: return 4
    if cy &lt; dy: return 2
    if cy > dy: return 1
    return 0

# Dataset
class NoCRoutingDataset(Dataset):
    def __init__(self, n, size):
        self.size=size
        self.inputs=[]
        self.labels=[]
        for _ in range(n):
            H=W=size
            src=(random.randrange(H),random.randrange(W))
            dst=(random.randrange(H),random.randrange(W))
            cur=(random.randrange(H),random.randrange(W))

            load=np.random.rand(H,W).astype(np.float32)
            maps=[np.zeros((H,W),dtype=np.float32) for _ in range(3)]
            maps[0][src]=1; maps[1][dst]=1; maps[2][cur]=1
            x=np.stack([load,*maps],axis=0)
            self.inputs.append(x)
            self.labels.append(xy_label(cur,dst))

        self.inputs=np.array(self.inputs)
        self.labels=np.array(self.labels)

    def __len__(self): return len(self.labels)
    def __getitem__(self, i):
        return torch.tensor(self.inputs[i]), torch.tensor(self.labels[i])

# CNN Model
class RouterCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.net=nn.Sequential(
            nn.Conv2d(4,32,3,padding=1), nn.ReLU(),
            nn.Conv2d(32,64,3,padding=1), nn.ReLU(),
            nn.AdaptiveAvgPool2d(1), nn.Flatten(),
            nn.Linear(64,64), nn.ReLU(),
            nn.Linear(64,5)
        )

    def forward(self,x): return self.net(x)

# Train / Eval
def train_epoch(model,loader,opt,lossfn):
    model.train(); correct=total=loss_sum=0
    for X,y in loader:
        X,y=X.to(DEVICE),y.to(DEVICE)
        opt.zero_grad(); out=model(X)
        loss=lossfn(out,y); loss.backward(); opt.step()
        loss_sum+=loss.item()*X.size(0)
        correct+=(out.argmax(1)==y).sum().item()
        total+=y.size(0)
    return loss_sum/total, correct/total

def eval_epoch(model,loader,lossfn):
    model.eval(); correct=total=loss_sum=0
    with torch.no_grad():
        for X,y in loader:
            X,y=X.to(DEVICE),y.to(DEVICE)
            out=model(X); loss=lossfn(out,y)
            loss_sum+=loss.item()*X.size(0)
            correct+=(out.argmax(1)==y).sum().item()
            total+=y.size(0)
    return loss_sum/total, correct/total

# Predict Path
moves={0:(0,0),1:(-1,0),2:(1,0),3:(0,1),4:(0,-1)}

def predict_path(model,size,src,dst,steps=16):
    H=W=size
    load=np.random.rand(H,W).astype(np.float32)
    cur=src; path=[cur]
    with torch.no_grad():
        for _ in range(steps):
            if cur==dst: break
            sm,dm,cm=[np.zeros((H,W),dtype=np.float32) for _ in range(3)]
            sm[src]=1; dm[dst]=1; cm[cur]=1
            x=torch.tensor(np.stack([load,sm,dm,cm])).unsqueeze(0).to(DEVICE)
            d=model(x).argmax(1).item()
            dx,dy=moves[d]
            nx,ny=cur[0]+dx,cur[1]+dy
            if 0&lt;=nx&lt;H and 0&lt;=ny&lt;W: cur=(nx,ny)
            else: break
            path.append(cur)
    return path

# RUN
N, SIZE = 5000, 4
train_ds = NoCRoutingDataset(N, SIZE)
train_len = int(0.8*len(train_ds))
train_ds, val_ds = torch.utils.data.random_split(train_ds,[train_len,len(train_ds)-train_len])

train_loader=DataLoader(train_ds,batch_size=64,shuffle=True)
val_loader=DataLoader(val_ds,batch_size=64)

model=RouterCNN().to(DEVICE)
lossfn=nn.CrossEntropyLoss()
opt=torch.optim.Adam(model.parameters(),lr=1e-3)

for e in range(10):
    tl,ta=train_epoch(model,train_loader,opt,lossfn)
    vl,va=eval_epoch(model,val_loader,lossfn)
    print(f"Epoch {e+1}: Train Acc={ta:.3f}, Val Acc={va:.3f}")

src,dst=(0,0),(3,3)
print("\nPredicted Path:", predict_path(model,SIZE,src,dst))


    </pre>

    <pre id="anifis">
        # AIM: To study and implement the augmentation of Nature Inspired Algorithm in a simulation tool using an Adaptive Neuro-Fuzzy Inference System (ANFIS) model.

import numpy as np
import matplotlib.pyplot as plt

def gaussian(x, c, sigma):
    return np.exp(-0.5 * ((x - c) / sigma) ** 2)

class SimpleANFIS1D:
    def __init__(self, n_rules=2, lr=0.01, seed=0):
        np.random.seed(seed)
        self.n_rules = n_rules
        self.centers = np.linspace(0.2, 2.8, n_rules) + 0.1 * np.random.randn(n_rules)
        self.sigmas = 0.5 + 0.1 * np.random.randn(n_rules)
        self.p = 0.5 * np.random.randn(n_rules)
        self.q = 0.5 * np.random.randn(n_rules)
        self.lr = lr

    def forward(self, x):
        M = np.stack([gaussian(x, c, s) for c, s in zip(self.centers, self.sigmas)], axis=1)
        wsum = np.sum(M, axis=1, keepdims=True)
        w_norm = M / (wsum + 1e-8)
        f = self.p * x[:, None] + self.q
        y = np.sum(w_norm * f, axis=1)
        return y, (x, M, w_norm, f, wsum)

    def step(self, x, y_true):
        y_pred, cache = self.forward(x)
        e = y_pred - y_true
        x_col = x[:, None]
        M, w_norm, f, wsum = cache[1], cache[2], cache[3], cache[4]

        # Gradients for consequent parameters
        dp = np.mean(e[:, None] * w_norm * x_col, axis=0)
        dq = np.mean(e[:, None] * w_norm, axis=0)

        # dy/dw term
        wf = M * f
        dy_dw = (f * wsum - np.sum(wf, axis=1, keepdims=True)) / (wsum**2)

        # Gradients of Gaussian membership function
        dM_dc = M * ((x[:, None] - self.centers) / (self.sigmas**2))
        dM_ds = M * (((x[:, None] - self.centers)**2) / (self.sigmas**3))

        grad_c = np.mean(e[:, None] * dy_dw * dM_dc, axis=0)
        grad_s = np.mean(e[:, None] * dy_dw * dM_ds, axis=0)

        # Update
        self.p -= self.lr * dp
        self.q -= self.lr * dq
        self.centers -= self.lr * grad_c
        self.sigmas -= self.lr * grad_s

        loss = 0.5 * np.mean((y_true - y_pred)**2)
        return loss

# -------- MAIN --------
if __name__ == "__main__":
    rng = np.random.RandomState(1)
    X = np.linspace(0, np.pi, 200)
    Y = np.sin(2 * X) + 0.05 * rng.randn(200)

    # Train-test split
    idx = rng.permutation(len(X))
    X_train, Y_train = X[idx[:140]], Y[idx[:140]]
    X_test, Y_test   = X[idx[140:]], Y[idx[140:]]

    # Model
    model = SimpleANFIS1D(n_rules=3, lr=0.05, seed=42)

    # Training
    losses = []
    for ep in range(500):
        loss = model.step(X_train, Y_train)
        losses.append(loss)
        if (ep+1) % 50 == 0:
            print(f"Epoch {ep+1} | Loss = {loss:.6f}")

    # Evaluation
    y_train_pred, _ = model.forward(X_train)
    y_test_pred, _ = model.forward(X_test)
    print("Train MSE:", np.mean((y_train_pred - Y_train)**2))
    print("Test MSE :", np.mean((y_test_pred - Y_test)**2))

    # Plot
    Xp = np.linspace(0, np.pi, 400)
    y_pred, _ = model.forward(Xp)

    plt.figure(figsize=(9,4))
    plt.subplot(1,2,1)
    plt.plot(losses); plt.title("Training Loss")

    plt.subplot(1,2,2)
    plt.scatter(X_train, Y_train, s=10)
    plt.scatter(X_test, Y_test, s=10)
    plt.plot(Xp, np.sin(2*Xp), label="True", linewidth=2)
    plt.plot(Xp, y_pred, label="ANFIS Pred", linewidth=2)
    plt.legend()
    plt.tight_layout()
    plt.show()

    </pre>

    <pre id="tsp">
        # To apply a genetic algorithm to solve the Traveling Salesman Problem and to find a approximate shortest route that visits all cities exactly once and return to the starting point.

import random, math
import matplotlib.pyplot as plt

def dist(a, b):
    return math.hypot(a[0] - b[0], a[1] - b[1])

def route_len(route, cities):
    return sum(dist(cities[route[i]], cities[route[(i+1)%len(route)]] ) for i in range(len(route)))

def rand_route(n):
    r = list(range(n))
    random.shuffle(r)
    return r

# --------- GA Operators ----------
def tournament(pop, fit, k=3):
    idx = max(random.sample(range(len(pop)), k), key=lambda i: fit[i])
    return pop[idx][:]

def crossover(p1, p2):
    a, b = sorted(random.sample(range(len(p1)), 2))
    child = [-1]*len(p1)
    child[a:b+1] = p1[a:b+1]
    fill = [x for x in p2 if x not in child]
    pos = 0
    for i in range(len(p1)):
        if child[i] == -1:
            child[i] = fill[pos]
            pos += 1
    return child

def mutate(r, rate=0.02):
    for i in range(len(r)):
        if random.random() &lt; rate:
            j = random.randrange(len(r))
            r[i], r[j] = r[j], r[i]

# --------- Genetic Algorithm ----------
def run_ga(cities, pop_size=200, gens=500, mut=0.02, cross=0.95):
    n = len(cities)
    pop = [rand_route(n) for _ in range(pop_size)]
    history = []

    for g in range(gens):
        dists = [route_len(r, cities) for r in pop]
        fit = [1/(d+1e-12) for d in dists]

        best_idx = min(range(pop_size), key=lambda i: dists[i])
        best_route, best_dist = pop[best_idx][:], dists[best_idx]
        history.append(best_dist)

        new_pop = [best_route[:]]      # elitism
        while len(new_pop) &lt; pop_size:
            p1 = tournament(pop, fit)
            p2 = tournament(pop, fit)
            child = crossover(p1, p2) if random.random() &lt; cross else p1[:]
            mutate(child, mut)
            new_pop.append(child)

        pop = new_pop

    return best_route, best_dist, history

# --------- Run Example ----------
random.seed(42)
cities = [(random.random()*100, random.random()*100) for _ in range(30)]
best_route, best_dist, hist = run_ga(cities, pop_size=300, gens=500)

print("Best distance:", best_dist)
print("Best route:", best_route)

# Convergence plot
plt.figure(figsize=(10,4))
plt.plot(hist); plt.title("GA Best Distance per Generation"); plt.xlabel("Gen"); plt.ylabel("Distance"); plt.grid(True)

# Best route plot
coords = [cities[i] for i in best_route] + [cities[best_route[0]]]
xs, ys = zip(*coords)

plt.figure(figsize=(6,6))
plt.plot(xs, ys, marker='o')
plt.title(f"Best Route (Dist {best_dist:.3f})")
plt.axis('equal')
plt.show()

    </pre>

    <pre id="discrete1">
        # noc_ga_compact.py
"""
Compact runner that uses noc_ga_lib.py.
Produces the same plots + JSON summary as before, but the logic is delegated
to the library for clarity and reuse.
"""

import random
import json
import os
import tempfile

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

#THIS LIB IS THE PRIMARY KEY FOR THE OPTIMIZED CODE
from noc_ga_lib import evolve_and_track_compact, save_summary

# ----------------------
# user parameters
# ----------------------
W, H = 4, 4
POP_SIZE = 20
GENS = 20
ELITE = 3
SEED = 42

# ----------------------
# run GA (library does the heavy lifting)
# ----------------------
def main():
    random.seed(SEED)
    np.random.seed(SEED)

    history, best, mesh_data = evolve_and_track_compact(
        W=W, H=H, pop_size=POP_SIZE, gens=GENS, elite=ELITE, seed=SEED
    )

    best_fitness, best_loads, best_routes = best
    _, _, edges = mesh_data

    # --- fitness plot ---
    plt.figure()
    plt.plot(history['best_fitness'], label='best fitness')
    plt.plot(history['avg_fitness'], label='avg fitness')
    plt.xlabel('Generation'); plt.ylabel('Fitness (lower better)')
    plt.title(f'GA Fitness over Generations ({W}x{H} demo)')
    plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

    # --- show best loads as DataFrame ---
    if best_loads is None:
        print("No valid solution found.")
    else:
        rows = [{'from': str(u), 'to': str(v), 'util': float(val)}
                for (u, v), val in zip(edges, best_loads)]
        df_links = pd.DataFrame(rows)
        print(df_links.head(12).to_string())

        # histogram
        plt.figure()
        plt.hist(df_links['util'], bins=15)
        plt.xlabel('Utilization (flits/cycle)')
        plt.ylabel('Number of directed links')
        plt.title('Histogram of directed link utilizations (best solution)')
        plt.grid(True); plt.tight_layout(); plt.show()

        # heatmaps (undirected aggregated)
        undirected = {}
        for (u, v), val in zip(edges, best_loads):
            key = tuple(sorted([u, v]))
            undirected[key] = undirected.get(key, 0.0) + float(val)

        coords = [(i % W, i // W) for i in range(W * H)]
        import numpy as _np
        horiz = _np.zeros((H, W - 1))
        vert = _np.zeros((H - 1, W))
        for (a, b), val in undirected.items():
            ax, ay = coords[a]
            bx, by = coords[b]
            if ay == by:
                x = min(ax, bx); y = ay; horiz[y, x] = val
            elif ax == bx:
                x = ax; y = min(ay, by); vert[y, x] = val

        plt.figure(); plt.imshow(horiz, aspect='auto'); plt.title('Horizontal edge loads'); plt.colorbar(); plt.tight_layout(); plt.show()
        plt.figure(); plt.imshow(vert, aspect='auto'); plt.title('Vertical edge loads'); plt.colorbar(); plt.tight_layout(); plt.show()

    # --- save summary via library helper ---
    summary_path = save_summary(history, best)
    print(f"✅ Saved serializable summary to: {summary_path}")

if __name__ == "__main__":
    main()

    </pre>

    <pre id="keywords">
        #Q1:Solving Discrete Routing Optimization in NoC using Evolutionary Genetic Algorithms.: discrete
        #Q1:If libracy given: Solving Discrete Routing Optimization in NoC using Evolutionary Genetic Algorithms.: discrete1
        #2 # To build a simple CNN that can learn and predict the next routing direction in Network-on-Chip (NoC) based on the current network state: cnn
        #3 # AIM: To study and implement the augmentation of Nature Inspired Algorithm in a simulation tool using an Adaptive Neuro-Fuzzy Inference System (ANFIS) model.: anifis
        #4 # To apply a genetic algorithm to solve the Traveling Salesman Problem and to find a approximate shortest route that visits all cities exactly once and return to the starting point.: tsp

    </pre>


    
   

    
</body>
</html>
